---
title: "Clasificación de Países Según Variables Socio-Económicas y Sanitarias"
subtitle: "Análisis Multivariado, Proyecto de Fin de Curso"
author: "Emanuelle Marsella, Maximiliano Saldaña"
date: "Julio, 2020"
output: pdf_document
toc: true
theme: united
pandoc_args: [
      "--number-sections",
      "--number-offset=1"
    ]

header-includes:
  - \usepackage{float}
  - \usepackage[spanish]{babel}

---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=FALSE,
                      include=FALSE,
                      warning = FALSE,
                      message = FALSE,
                      fig.pos = 'H',
                      fig.align = 'center',
                      out.extra = '',
                      fig.hold = 'hold'
                      )
options(xtable.comment=FALSE,
        xtable.table.placement="H")
```



\maketitle

\newpage


```{r, include = FALSE}
library(dplyr)
library(ggplot2)
library(xtable)
library(FactoMineR)
library(forcats)
library(gridExtra)
library(factoextra)
library(ggdendro)
library(NbClust)
library(cluster)
library(MASS) 
library(heplots) 
library(StatMatch)
library(GGally)
library(pROC)
library(caret)
library(nnet)
library(AER)


source("indicadores.R")
source("testes.R")
```




```{r lectura de datos, echo=FALSE}
#Lectura de los datos

datos <- read.table("corona.txt", sep = "\t", header = TRUE)

datos <- datos  %>% rename(healthexp= "currenthealthexpenditureofgdpshx", gdppercap = "gdppercapitaconstant2010us" )
```

```{r imputacion, echo=FALSE}

dim(datos)
(NAcheck <- as.numeric(apply(is.na(datos), 2, sum)))

#Hay NAs en varias variables, una opción de imputación, en las cuantitativas imputar la media y en las cualitativas el modo. Stringency tiene 93 NAs (evaluar sacarla)

#vector de valores medios

vals_meds <- rep(0, dim(datos)[2])

for(j in 1:dim(datos)[2]){
  
  vals_meds[j] <- mean(datos[,j], na.rm = TRUE)
}

#imputación de vals medios en NAs

for(j in 1:dim(datos)[2]){
  if(NAcheck[j]>0){
    
    for(i in 1:dim(datos)[1]){
      if(is.na(datos[i,j])==TRUE){
       datos[i,j] <- vals_meds[j] 
    }
    }
  }
}

```

```{r}

datos <- datos %>% 
  mutate(noinfectionrate = 1-infectionrate)

vars.acp <- c("medage", "gdppercap", "healthexp", "hospitalbed", "noinfectionrate", "CESI_INDEX")



acp <- PCA(datos[, vars.acp], quanti.sup = 6)


```

# Resumen ejecutivo

En este trabajo se aplican técnicas de clasificación (Análisis de Cluster y Análisis Discriminante) a una base de datos que contiene información a marzo de 2020 referente a variables socio-económicas, sanitarias y la tasa de infección de COVID-19. Se logra una clasificación en 4 grupos mediante el análisis de cluster jerárquico agregativo y se emplean estos grupos para un análisis discriminante logístico, que el modelo clasifica en general bien.

# Introducción

Se busca aplicar técnicas de clasificación al conjunto de países estudiado en *Economic Policy Responses to a Pandemic: Developing the COVID-19 Economic Stimulus Index* (Ceyhun Elgin, Gokce Basbug, Abdullah Yalaman; 2020), contándose con variables de carácter socio-económico y sanitario (en particular la tasa de infección de COVID-19 de los países) a marzo de 2020. También se cuenta con las componentes principales construidas en *Aplicación del Análisis de Componentes Principales a Variables Económicas y Vinculadas al COVID-19* (Marsella y Saldaña, 2021). Inicialmente se buscará clasificar los países con un análisis de cluster a partir de un subconjunto de las variables con las que se cuenta (las componentes principales y el índice de estímulo económico) y caracterizarlos, para posteriormente usar estos grupos en un análisis de discriminante, con la intención de encontrar una regla de clasificación para discriminar entre los grupos a partir de las variables con las que se cuenta.

# Breve descripción de los datos

Se cuenta con 166 observaciones correspondientes a países y 8 variables en total, un subconjunto de 6 variables de las extraídas de (Ceyhun Elgin, Gokce Basbug, Abdullah Yalaman; 2020) y dos de las componentes principales construidas en Marsella y Saldaña (2021). Estas variables son:

* *medage*: edad mediana en el país

* *noinfectionrate*: tasa de de no infección, representa la proporción de la población total del país no infectada de COVID-19

* *hospitalbed*: camas de hospital por cada 1000 personas

* *healthexp*: gastos en salud, expresados como porcentaje del PBI

* *gdppercap*: PBI per cápita del país en dólares a niveles de 2010

* *CESI_INDEX*: índice de estímulo económico.

* Dim.1 y Dim.2: Primeras dos componentes principales construidas en el primer proyecto de Análisis Multivariado.

Durante el informe se referenciará información referente a las variables que se obtuvo en Marsella y Saldaña (2021). 


# Análisis de Cluster

Inicialmente se plantearon varios análisis de cluster teniendo en cuenta distintos conjuntos de las variables disponibles: las originales de la base empleadas para realizar análisis de componentes principales en el trabajo de mitad de curso de Análisis Multivariado (Marsella y Saldaña, 2021),  y otro compuesto por las componentes principales obtenidas en ese mismo trabajo. Se aplicaron métodos de cluster agregativo, empleando el método de Ward, el del vecino más cercano y el del vecino más lejano, buscando explorar las distintas opciones con las que se cuenta para ver cuál funciona mejor para nuestros datos. En *Marsella y Saldaña (2021)* se observó que algunos países presentan un comportamiento atípico, el cual se debe tener en cuenta al aplicar las técnicas de cluster dado que algunos métodos son más susceptibles que otros a la presencia de observaciones de este tipo. Para elegir el mejor método de clasificación y la cantidad de grupos nos valimos de las reglas de detención y las siluetas de los grupos, así como también las representaciones gráficas (dendrogramas) para los cluster jerárquicos utilizados.


Dado que la cantidad de observaciones con las que se cuenta originalmente (166) no es muy elevada, se optó por aplicar los métodos de clusters jerárquicos en lugar de no jerárquicos, que trabajan con particiones encajadas del conjunto de observaciones. Por esta misma razón se optó por utilizar métodos agregativos en lugar de divisivos. Los otros métodos de agrupación se consideraron para contar con alternativas, los resultados que dieron se encuentran presentados en el Anexo, incluido en el script de este trabajo. En los métodos agregativos se parte de un conjunto de $I$ clusters donde cada uno está formado por una observación y se llega en el paso final a un cluster con las $I$ observaciones. Adicionalmente para aplicar métodos de cluster se debe definir una métrica que emplee los valores de las variables de cada objeto para determinar qué tan cerca está uno (individuos o clusters) de los otros,  y además debe ser elegido un algoritmo para unir grupos entre si y observaciones a grupos.


El conjunto de variables finalmente utilizadas para aplicar los métodos de cluster son el Índice de Estímulo Económico *CESI_INDEX* construido en el trabajo original *Ceyhun Elgin, Gokce Basbug, Abdullah Yalaman (2020)* y replicado en *Marsella y Saldaña (2021)*, así como las primeras dos Componentes Principales construidas a partir de un ACP en este último trabajo. En particular, se había observado que estas dos componentes principales lograban explicar en su conjunto el 72.77% de la nube de puntos conformadas por los 166 individuos y las variables *medage*, *gdppercap*, *healthexp*, *hospitalbed* y *noinfectionrate*, por lo cual consideramos que pueden ser un buen insumo para la clasificación. Adicionalmente se incluye la variable *CESI_INDEX* debido a que no se terminó empleando para la construcción de las componentes y su representación en el primer plano plano no era muy buena como se desarrolló en el primer proyecto del curso.




```{r}
vars_cluster <- vars.acp
vars_cluster1 <- c("fiscal", "ratecut", "macrofin", "bopgdp", "medage", "gdppercap", "healthexp", "hospitalbed", "infectionrate")

#round(cor(datos[,vars_cluster1], ),2)
```

```{r correlaciones, include=TRUE, results='asis'}
datos_acp <- acp$ind$coord[,1:2]
datos_acp <- cbind(as.data.frame(datos_acp), "CESI_INDEX" = datos[,c("CESI_INDEX")])

round(cor(datos_acp, ),2) %>% as.data.frame() %>%
  xtable(caption="Matriz de correlaciones de las variables a utilizar en los métodos de cluster.")

```

Por construcción, las correlaciones entre las componentes principales (*Dim.1* y *Dim.2*) son 0, mientras que el *CESI_INDEX* se correlaciona principalmente con la primer componente principal más que con la segunda, como habíamos visto en el primer trabajo. Dado que 0.52 se podría considerar como una correlación relativamente alta, optamos por utilizar la distancia de Mahalanobis que incluye la matriz de varianzas y covarianzas y así asegurarnos de que esa correlación no tenga una gran influencia  en la formación de los grupos. Dicha distancia está definida como:

$$d_{ij}^2 = (x_{ik} - x_{jk})'\Sigma^{-1}(x_{ik} - x_{jk})$$

Donde $i$ y $j$ son dos individuos y $\Sigma$ es la matriz de varianzas y covarianzas de las variables. 

Como fue anteriormente mencionado, además de la métrica es necesario optar por un algoritmo para definir como unir grupos y observaciones a grupos. Inicialmente consideramos dentro de los métodos jerárquicos agregativos los métodos del vecino más cercano, vecino más lejano y método de Ward.

```{r cluster vecinos, include=TRUE, out.width= "100%", fig.cap="Dendrogramas para las clasificaciones realizadas con vecinos más cercanos y más lejanos."}
rownames(datos_acp) <- datos$country

datos_acp_st <- scale(datos_acp)
cov_datos_acp <- cov(datos_acp_st)

dist_maha <- mahalanobis.dist(datos_acp_st)

clust2.1 <- agnes(dist_maha, method = "single", diss = TRUE)

clust2.2 <- agnes(dist_maha, method = "complete", diss = TRUE)

labs <- datos$country[as.logical(c(rep(c(1,0,0), 54), 0, 1, 1, 1))]

dend.1 <- fviz_dend(clust2.1,cex=0.4, lwd=0.35, show_labels = FALSE) +
  ggtitle("Vecinos más cercanos") +
  ylab("Altura")  #se puede notar a san marino como outlier 

dend.2 <- fviz_dend(clust2.2,cex=0.4, lwd=0.35, show_labels = FALSE) +
  ggtitle("Vecinos más lejanos") +
  ylab("Altura")  #se pueden notar que san marino Islandia y Luxemburgo son los últimos en agruparse

grid.arrange(dend.1, dend.2, ncol=2)


```

En la Figura 1 se pueden ver los dendrogramas para los métodos del vecino más cercano y del vecino más lejano, los cuales son representaciones gráficas de la historia de agrupación que parte de los $I$ cluster iniciales y llega a un único cluster que contiene las $I$ observaciones. En ambos casos se puede ver que hay un conjunto de observaciones que son las últimas en ser agrupadas, dado que son las más distantes de las demás observaciones en la métrica utilizada, estas son las observaciones con valores atípicos de las variables que ya habían sido detectadas en el trabajo anterior (San Marino, Islandia y Luxemburgo, siendo San Marino la última de todas en ser agrupada). Este resultado era esperable, dado que estos métodos son muy susceptibles a la presencia de observaciones atípicas. El método elegido finalmente es el de Ward, el cuál se basa en agregar grupos minimizando la variabilidad dentro de los nuevos grupos formados, que necesariamente aumenta al realizar la unión de objetos heterogéneos pero se busca que aumente lo menos posible. Como contraparte se busca maximizar la varianza entre los grupos en la nueva estructura, para así lograr clusters lo más heterogéneos posibles entre si. Este método cuenta con una menor susceptibilidad a los valores atípicos y por eso resulta deseable emplearlo en nuestro caso.


```{r clust acp ward}
cluster_acp <- agnes(dist_maha, method = "ward", diss = TRUE)


```


```{r dendrograma ward, include =TRUE, fig.cap="Dendrogramas para la clasificación realizada por el método de Ward", out.width="75%"}
fviz_dend(cluster_acp,cex=0.4, show_labels = FALSE, lwd=0.35) +
  ggtitle("Método de Ward") +
  ylab("Altura") +
  theme(axis.text = element_text(size=15),
        axis.title = element_text(size=15)
        )

```

En la Figura 2 se ve todavía la presencia de atípicos, en el grupo conformado por San Marino, Luxemburgo e Islandia (en los otros dos métodos anteriores San Marino era agrupada únicamente en el último paso), si se elegía una estructura de dos clusters en los métodos anteriores uno de ellos incluía solo a San Marino y el otro al resto de las observaciones, mientras que empleando el método de Ward si se eligen 2 clusters no se observa eso. Al estar trabajando con un método jerárquico necesitamos tomar la decisión de qué estructura de grupos es la elegida, esto es, por cuántos grupos se opta. Para hacer esta elección se recurre a las reglas de detención, que pueden ser globales (evalúan la bondad de particionar en un número determinado de clusters) o locales (sirven para analizar si al unir dos grupos la estructura representa una mejoría). Se toman cuenta las reglas de detención locales del $pseudo-F$, $pseudo-t^2$ y la global del $R^2$, debiendo ser consideradas en conjunto. El $pseudo-F$ permite ver qué tan grande es la suma de las variaciones entre los grupos (la variación explicada) respecto a la suma de variaciones en los grupos (variación residual). Como se busca que los grupos sean disímiles entre sí, se busca que el valor del $pseudo-F$ para la estructura de grupos considerada sea alto, comparándose respecto al valor para la estructura que tiene un cluster más y la que tiene uno menos, es decir, se toma en cuenta la estructura que tiene un valor máximo local del $pseudo-F$. Por otro lado, el $pseudo-t^2$ permite observar si al pasar de $k+1$ a $k$ grupos hay un incremento de la variabilidad dentro de los grupos. Si en el paso $k+1$ el valor del $pseudo-t^2$ disminuye con respecto al que toma en el paso $k$ entonces es conveniente quedarse con la estructura de $k+1$ grupos, ya que esto implica que en esta última la variabilidad de dentro de los grupos es menor, es decir, son más homogéneos en su interior. Finalmente, como regla global se  emplea el valor del  $R^2$, que expresa la proporción de la variabilidad total explicada por la estructura elegida. Con esta regla de detención nos quedamos con la estructura que al considerar un grupo más el  $R^2$ no siga aumentando considerablemente, aquella donde se estabilice el valor. 


```{r indicadores}
cluster_acp_inds <- indicadores(cluster_acp$merge ,datos_acp ,9 )
```



```{r indicadores xtable, results='asis', include = TRUE}

xtable(cluster_acp_inds, caption = "Valores de los indicadores de las Reglas de Detención del método elegido.") %>% print.xtable(include.rownames = FALSE)
```



En el Cuadro 2 están presentados los valores que se toman en cuenta para aplicar las reglas de detención, a partir de los cuales hay dos estructuras de grupos de interés. En primer lugar consideramos una estructura de dos grupos que surge de unir el grupo de 58 observaciones creado en el paso anterior y otro de 3 conformado por San Marino, Luxemburgo e Islandia, como se podía observar en la Figura 2. Para esta estructura el valor del $pseudo-t^2$ es 20.58, lo que representa una disminución respecto a la estructura con un grupo y no se da una disminución al considerar la estructura con tres grupos. En cuanto al $pseudo-F$ el valor (108.44) representa un máximo relativo. La otra estructura considerada es de cuatro grupos y cuenta con un valor del $pseudo-t^2$ de 16.22 y un $pseudo-F$ de 91.54 que representan un mínimo y un máximo local respectivamente. Por lo tanto según estos dos indicadores cualquiera de estas dos estructuras de grupos puede resultar adecuada. En lo que se diferencian además de la cantidad de grupos es en sus valores del $R^2$, que aunque necesariamente será mayor al considerar más grupos para la estructura de dos grupos es de 0.4 y para la de cuatro es de 0.63, por lo cual tenemos un aumento aproximado del 23% de la variabilidad explicada al considerar cuatro grupos y solo siendo el aumento al considerar 5 grupos de 5%, argumentos a favor de elegir 4 clusters. 



```{r siluetas}
silueta_acp <- silhouette(cutree(cluster_acp , 2) , dist_maha)
silueta_acp2 <- silhouette(cutree(cluster_acp , 4) , dist_maha)


#gráfico de silueta, vemos que hay un conjunto de observaciones del grupo 2 con valores negativos
sil1 <- fviz_silhouette(silueta_acp, print.summary = TRUE, label = TRUE) + coord_flip() 
sil2 <-fviz_silhouette(silueta_acp2, print.summary = TRUE, label = TRUE) + coord_flip() 


silprom1 <- sil1[[1]] %>% group_by(cluster) %>% summarise(sil_mean = round(mean(sil_width),2), meannames = mean(as.numeric(name)))


silprom2 <- sil2[[1]] %>% group_by(cluster) %>% summarise(sil_mean = round(mean(sil_width),2)) %>% cbind(cord = c(40, 115, 140, 161 ))


```


```{r graficos de silueta, , include= TRUE, fig.cap= "Gráficos de silueta para las dos estructuras de grupos propuestas.", out.width= "85%" }
grafsiluetas1 <-  sil1+geom_text(data = silprom1, mapping = aes(y= 0.8, x = as.character(meannames), label = paste("Silueta promedio:", as.character(sil_mean)))) + theme(axis.text.y=element_blank(), axis.ticks.y=element_blank()) + ggtitle("Silueta promedio: 0.34") + ylab("Ancho de silueta")

grafsiluetas2 <- sil2+geom_text(data = silprom2, mapping = aes(y= 0.8, x = cord, label = paste("Silueta promedio:", as.character(sil_mean)))) + theme(axis.text.y=element_blank(), axis.ticks.y=element_blank()) + ggtitle("Silueta promedio: 0.34") + ylab("Ancho de silueta")


grid.arrange(grafsiluetas1, grafsiluetas2)
```
Otro indicador adicional para la selección de la estructura de grupos es la silueta de las observaciones y la representación gráfica de la misma. La silueta $s_i$ de la observación $i$ se calcula como:

$$s_i = \frac{b_i - a_i}{max(b_i, a_i)}$$

donde $a_i$ es la distancia promedio de la i-ésima observación al resto de objetos de su grupo y $b_i$ es la distancia promedio de la observación a los objetos de los demás grupos. Así se tiene una medida de la similaridad de una observación respecto a las que están en su grupo y las que no. Entre más próximo a 1 sea el valor de la silueta más similar es la observación a las de su mismo grupo y más disímil a las de los demás. Una silueta próxima a -1 indica lo contrario. 

Analizando los gráficos de siluetas y los valores presentados en la Figura 3 se aprecia que para ambas estructuras de grupo la silueta promedio de todas las observaciones toma un valor de 0.34 aproximadamente. Sin embargo observándose la silueta promedio dentro de cada uno de los grupos en la estructura de dos grupos la silueta promedio de uno de ellos es negativa y próxima a 0, lo que indica que en promedio la distancia de las observaciones a las demás de su mismo grupo es casi igual a las distancia de las observaciones a las del otro grupo. Esto es consecuencia del elevado número de observaciones con silueta negativa en el grupo 2, aproximadamente la mitad, las cuales son más similares a las observaciones del grupo 1, lo cual no es deseado para hacer una buena clasificación. Para la estructura de 4 grupos si bien el promedio global de las siluetas es igual al de la otra estructura vemos que ninguno de los grupos tiene siluetas promedio negativas y la menor es de 0.11. Esto indicaría que las observaciones están mejor asignadas en sus grupos al considerar cuatro de ellos.

En conclusión, tomando en cuenta su mejor desempeño en cuanto al $R^2$ y las siluetas promedio de los grupos, se opta por la estructura de cuatro clusters en lugar de la de dos.



## Descripción de los clusters

```{r grupos 4 cluster, include = TRUE, out.width="75%", fig.cap="Gráfico de las proyecciones de los países en el primer plano principal, coloreados por cluster."}
grupos_acp2 <- cutree(cluster_acp, 4)

graf2 <- as.data.frame(cbind(datos_acp, grupos_acp2))

ggplot(graf2) + geom_point(aes(x=Dim.1,y= Dim.2, color = as.factor(grupos_acp2), label = row.names(graf2))) +
  geom_text(aes(x=Dim.1,y= Dim.2, label=ifelse((Dim.1>2.5 & (Dim.2 > 2.5 | Dim.2 < -2.5)) | (Dim.1 > 3.7) | (Dim.2 > 2), as.character(row.names(graf2)),'')),hjust=0.7,vjust=-0.2) +scale_color_discrete(name= "cluster") + geom_hline(yintercept = 0) + geom_vline(xintercept = 0) 


```

En la Figura 4 se puede observar el gráfico de los países proyectados en el primer plano principal, conformado por las dos componentes principales empleadas en la formación de los clusters. De acuerdo a la caracterización de los ejes realizada en *Marsella y Saldaña, (2021)* la dimensión 1 se caracteriza por el desarrollo económico de los países, donde mayores valores de esta dimensión significan un mayor desarrollo económico; también se correlaciona positivamente esta dimensión con la variable *infectionrate*, lo cual habíamos encontrado que era una consecuencia de que los países con mayor desarrollo económico eran aquellos que presentaban tasas de infección más altas a marzo de 2020. En cuanto a la dimensión 2, se correlaciona principalmente con la tasa de infección de forma negativa: valores altos de la variable Dim.2 significan bajas tasas de infección. Si bien no tenemos en cuenta para los gráficos el Índice de Estímulo Económico, *CESI_INDEX*, pues solo podemos representar los puntos en el plano, las correlaciones de esta variable son de 0.52 con la dimensión 1 y -0.09 con la dimensión 2, por lo cual esperamos que el comportamiento de los individuos de cada grupo para esta variable tenga similaridad al que muestran para la dimensión 1.

Lo primero que se puede observar es que el grupo 4 es el que más se aleja de los demás, dado que las observaciones que lo componen tomaron valores altos de las dos variables consideradas (que a su vez considerando el conjunto de las variables con las que se formaron las componentes, tomaban valores atípicos, en particular en las variables *infectionrate* y *gdppercap*). Así, por tomar valores altos de la dimensión 1 y valores bajos de la dimensión 2, los países de este cluster son aquellos que presentan alto desarrollo económico y altas tasas de infección. Las observaciones del grupo 1 son las que toman valores más bajos en la dimensión 1, por lo cual son países de menor desarrollo económico y bajas tasas de infección, donde esto último también se ve reflejado en los valores medios que toman en la dimensión 2. Los países del grupo 2 presentan niveles bajos de la dimensión 1 y altos de la dimensión 2, lo que se corresponde con un menor nivel de desarrollo económico (salvo atípicos dentro del grupo como Japón y Corea del Sur) y bajos niveles de infección. Por su parte, el grupo 3 contiene observaciones con valores altos de la dimensión 1 y bajos de la dimensión 2, lo que representa un alto nivel de desarrollo económico y altas tasas de infección, que podemos ver en países como Suiza.


```{r boxplot noinfectionrate, include=TRUE, out.width="85%", fig.cap="Gráficos de cajas de la tasa de infección, PBI per cápita e índice de estímulo económico, para los distintos grupos."}
datos_disc_multinom <- as.data.frame(cbind(datos[,vars_cluster], graf2[,-3]))

grid.arrange(
  ggplot(datos_disc_multinom) +
    geom_boxplot(aes(x = as.factor(grupos_acp2), y = 1-noinfectionrate))+
    xlab("Grupos")+
    ylab("Tasa de infección"),
  ggplot(datos_disc_multinom) +
    geom_boxplot(aes(x = as.factor(grupos_acp2), y = gdppercap))+
    xlab("Grupos")+
    ylab("PBI per cápita"),
  ggplot(datos_disc_multinom) +
    geom_boxplot(aes(x = as.factor(grupos_acp2), y = CESI_INDEX))+
    xlab("Grupos")+
    ylab("Índice de Estímulo Económico"),
  ncol=3
  )

```
En la Figura 5 se realizan gráficos de cajas para las variables *infectionrate* y *gdppercap* para cada uno de los 4 grupos, buscando verificar si la caracterización de los grupos que realizamos en base a las componentes principales se ve reflejada en estas dos variables, que fueron empleadas para su elaboración[^1]. Incluimos también los mismos gráficos para la variable *CESI_INDEX*, que no pudimos representar en el anterior gráfico en dos dimensiones, para verificar si como suponíamos se comporta de manera similar a la dimensión 1 para cada grupo. Efectivamente, se observa que para la tasa de infección, el grupo 4 es el que presenta mayores valores de esta variable mostrando altos niveles de infección[^2], seguido por el grupo 3 con valores altos aunque no tan extremos, mientras que los otros dos grupos muestran niveles bajos de infección. Para la variable PBI per cápita, vemos que los grupos 3 y 4 son los que toman valores más altos de la variable, seguidos por los grupos 1 y 2 (este último cuenta con un outlier, Japón, al nivel de los otros grupos). Estas observaciones se corresponden a grandes rasgos con lo que se observaba en la Figura 4. En cuanto al *CESI_INDEX*, vemos que los grupos 3 y 4 presentan niveles similares de la variable lo cual es consistente con el comportamiento de ambos grupos en la dimensión 1, mientras que a su vez los grupos 1 y 2 muestran también comportamientos similares entre sí, si bien se observa la presencia de algunos outliers en el grupo 1; el comportamiento del *CESI_INDEX* es así muy similar al de la variable *gdppercap*, algo razonable dado que esta variable es de índole económico, fue utilizada para la construcción de los componentes principales y en particular presenta una correlación relativamente alta con la dimensión 1.




[^1]: Graficamos *infectionrate* en lugar de *noinfectionrate* para una mejor lectura e interpretación de los gráficos
[^2]: Se debe tener en cuenta que el grupo 4 cuenta con solo 3 observaciones, por lo cual el gráfico de caja no es la representación más adecuada, no obstante se incluye el gráfico para este grupo para realizar la comparación con el resto de los grupos.




# Análisis discriminante 

Luego de haber agrupado las observaciones empleando como variables dos de las componentes principales y el índice de estímulo económico, resulta de interés profundizar en el análisis de la estructura de grupos mediante un análisis discriminante. En este método de clasificación supervisada haremos uso de la variable que nos indica a cuál de los cuatro grupos anteriormente conformados pertenece cada observación y un conjunto de variables para encontrar una regla de clasificación que permita hacer distinción entre los grupos que ya se cuenta. En nuestro caso nos resulta de interés hacer uso del conjunto de variables que se usó para obtener las componentes principales que se tomaron en cuenta para asignar las observaciones a los distintos grupos y así ver de qué manera nos permiten distinguir estos últimos. El conjunto de variables empleado es entonces:

* *medage*
* *gdppercap*
* *healthexp*
* *hospitalbed*
* *noinfectionrate*
* *CESI_INDEX*

Donde se incluye el índice de estímulo económica a pesar de no haber sido utilizado en la creación de las componentes para observar su efecto en la clasificación. Dado que en este conjunto de variables todas son cuantitativas una opción puede ser realizar un análisis discriminante lineal, donde se parte del supuesto que en cada grupo $g=1,...,k$ existe una distribución normal $p$-variada con vector de medias $\mu_g$ y matriz de varianzas y covarianzas $\Sigma_g$, siendo p el número de variables. Otro supuesto adicional es que para los distintos grupos las matrices $\Sigma_g$ son iguales. De cumplirse ambos supuestos se pueden derivar las funciones discriminante y de clasificación en base a ellos y la regla de clasificación elegida. Para evaluar su cumplimiento se realizan pruebas de hipótesis de multinormalidad y de homocedasticidad. La prueba de multinormalidad empleada es la de Mardia, que pone a prueba las hipótesis nulas de  simetría y curtosis de las distribuciones de los grupos. Para no rechazar la multinormalidad no se tiene que rechazar ninguna de las hipótesis. En el Cuadro 3 se aprecia como para los cuatro grupos a un nivel de significación del 5% se rechaza la hipótesis nula de multinormalidad, al rechazarse una o ambas de las hipótesis anteriormente presentadas (observando los p-valores para los grupos 2 y 4 la hipótesis de simetría no se rechaza pero la de curtosis sí, en los otros dos se rechazan ambas hipótesis). Por lo tanto, el análisis discriminante lineal queda descartado, lo mismo que el cuadrático que se emplea para casos donde no se cumple la homocedasticidad pero que sí exige que se cumpla la normalidad. 

```{r}
# a nivel de cada una de las variables se puede ver que no hay campanas con forma normal para cada uno de los grupos, lo cual indicaría que las distribuciones de los grupos no podrían ser multinormales 

# ggpairs(datos_disc_multinom[,c("medage", "gdppercap", "healthexp", "hospitalbed", "noinfectionrate", "CESI_INDEX")],  mapping = ggplot2::aes(color = as.factor(datos_disc_multinom$grupos_acp2) , alpha = 0.5), 
#         diag = list(continuous = wrap("densityDiag")), 
#         lower=list(continuous = wrap("points", alpha=0.9)))
```

```{r tests norm 4 clust}

sing4 <- datos_disc_multinom %>% filter(grupos_acp2 != 4)


pruebasnorm2 <- testes(sing4[,c("medage", "gdppercap", "healthexp", "hospitalbed", "noinfectionrate", "CESI_INDEX")], sing4$grupos_acp2)

# hay un problema con es test de homocedasticidad (bajo numero de observaciones en grupo 4 posible problema), pero ya podemos concluir a partir del de normalidad 
pruebasnorm <- testes(datos_disc_multinom[,c("medage", "gdppercap", "healthexp", "hospitalbed", "noinfectionrate", "CESI_INDEX")], datos_disc_multinom$grupos_acp2)
pruebasnorm2 <- testes(sing4[,c("medage", "gdppercap", "healthexp", "hospitalbed", "noinfectionrate", "CESI_INDEX")], sing4$grupos_acp2)


matriz_tnorm <- rbind(
  as.integer(c(1     ,  56.8888077,   0.4417598, -15.8470844 ,  0.0000000, 105.0000000)), 
  c(2     ,  4.533441e+01,  8.451587e-01, -5.223915e+00,  1.751788e-07,  2.500000e+01),
  c(3     ,   12.52814,   1.00000, -11.69642,   0.00000,  33.00000),
  c(4     ,   4.118525e-02,  1.000000e+00, -4.110058e+00,  3.955595e-05,  3.000000e+00) 
)


colnames(matriz_tnorm) <-   c("grupo", "kappa1", "pvalsim", "kappa2", "pvalkurt", "n")


```

```{r, results='asis', include= TRUE}
xtable(as.data.frame(matriz_tnorm), round = 2, caption="Valores de los estadísticos y p-valores para los test de simetría y curtosis.") %>% print.xtable(include.rownames = FALSE)
```

Ante esta situación se opta por efectuar un análisis discriminante logístico, para el cual no se requiere el cumplimiento de la multinormalidad. Como tenemos más de dos grupos donde cada observación va a tener una probabilidad de pertenecer a cada uno de ellos, consideramos un conjunto de variables aleatorias $Y_i \sim multinomial(n, \pi_g)$, siendo $Y_i$ el grupo al que corresponde la observación $i$-ésima. En este modelo, según el método de la categoría de referencia, se emplean $k-1$ ecuaciones, para modelar la probabilidad de que una observación esté en el grupo $g$ respecto a la probabilidad de que esté en el grupo que se toma como referencia (en el caso del modelo planteado es el grupo 1). La probabilidad que el individuo $i$ esté en el grupo $g$ es:

$$\pi_{i,g} = P(y_i = g) = \frac{exp(x_i^t\beta_g)}{\sum_{j=1}^k exp(x_{ij}^t\beta_j)}$$

donde $x_i$ es el vector con los valores de las variables para el individuo $i$ y $\beta_g$ es un vector de coeficientes a estimar para el grupo $g$. Las funciones de enlace serían:

$$log_e \left[\frac{\pi_{ig}}{\pi_{ik}}\right]= x_i^t \beta_g, \,\forall \; g=1,...,k-1$$

En particular, en nuestro caso contamos con cuatro grupos, por lo que el modelo contará con tres ecuaciones y funciones de enlace para cada observación, donde:

$$x_i^t \beta_g= \beta_{0g} + \beta_{1g}medage_i + \beta_{2g}gdppercap_i + \beta_{3g}healthexp_i + \beta_{4g}hospitalbed_i$$
$$ + \beta_{5g}noinfectionrate_i + \beta_{6g}CESI\_INDEX_i$$

$\forall \,\, i= 1,...,166$ y $\forall \;g=1,2,3$.



```{r modelo multinom}
mod_multinomial <- multinom(as.factor(grupos_acp2) ~ gdppercap + medage + noinfectionrate + healthexp + hospitalbed + CESI_INDEX   ,  data=datos_disc_multinom) 



resumen_multinom <- summary(mod_multinomial)
```



Los parámetros del modelo se estiman maximizando la función de verosimilitud de los parámetros $\beta_g$ con métodos computacionales, en particular el método de Newton-Raphson (con el algoritmo Broyden-Fletcher-Goldfarb-Shanno). Se realiza la prueba de significación conjunta del modelo, donde se pone a prueba la hipótesis nula:

$$H_0) \begin{pmatrix} \beta_{11}\\ \beta_{12} \\ \beta_{13} \end{pmatrix}  = \begin{pmatrix}\beta_{21}\\ \beta_{22} \\ \beta_{23}\end{pmatrix}  = ... = \begin{pmatrix}\beta_{61}\\ \beta_{62} \\ \beta_{63}\end{pmatrix}  = \begin{pmatrix}0\\ 0 \\ 0 \end{pmatrix}$$
donde la hipótesis alternativa es que alguno de los vectores de parámetros de las variables sea distinto al vector nulo. Se emplea el estadístico *Deviance* que resulta equivalente al de razón de verosimilitud $-2log \frac{L_R}{L_c}$ ($L_R$ es la verosimilitud del modelo con solo la constante y $L_c$ la del modelo con todas las variables). Bajo $H_0$ cierta este estadístico se distribuye $\chi^2_{(k-1)(J)}$ (Hosmer y Lemeshow, 2000,  p. 270) donde $J$ es el número de variables explicativas del modelo. En nuestro caso $k=4$ y $J=6$ y para el conjunto de variables consideradas $-2log \frac{L_R}{L_c} = 293.42 > 9.39= \chi^2_{18,0.05}$; por lo que rechazamos la hipótesis nula y entonces el modelo en su conjunto resulta significativo al 5%.    

```{r contraste de sig modelo}
#significación del modelo

mod_multinomial_sinvars <- multinom(as.factor(grupos_acp2) ~ 1 ,  data=datos_disc_multinom) 

D1 <- mod_multinomial_sinvars$deviance - mod_multinomial$deviance
pchisq(D1, df = (4-1)*(6), lower.tail = F)

qchisq(0.05, df = 18)
D1
```

 
Para evaluar qué variables mantenemos en el modelo efectuamos las pruebas de significación individuales para cada una. En este caso evaluamos la significación de cada variable para cada una de las 3 ecuaciones del modelo. La hipótesis nula es $H_0) \beta_{gj} = 0$, con $g=1,2,3$ y $j=1,...,6$ y se hace uso del estadístico de Wald $z^* = \frac{\hat{\beta}_k}{s_{\beta_k}}$ (bajo $H_0$ cierta $z^* \sim N(0,1)$) y se rechaza $H_0$ si $|z^*|> z_{1-\alpha/2}$. En el caso del modelo planteado, para las tres ecuaciones consideradas todas las variables resultan significativas al 5%, dados que los p-valores son menores que 0.05 (cuadro completo en el Anexo). Esto implica que todas las variables consideradas resultan relevantes para separar los grupos, no hay ninguna de las que se empleó para construir las componentes principales con las que se agruparon los países que no aporte a la clasificación y por lo tanto se conservan todas en el modelo.  


```{r contrases individuales de las vars}

tests_wald_multinom <- coeftest(mod_multinomial)

#MANUALMENTE

# significación de las variables

# coeficientes <- resumen_multinom$coefficients
# desvios <- resumen_multinom$standard.errors
# 
# ## 1er modelo (grupo 2)
# 
# wald1 <- coeficientes[1,]/desvios[1,]
# 
# pnorm(abs(wald1), lower.tail = FALSE)
# pchisq(wald1^2, df = 1, lower.tail = F)
# 
# qnorm(0.05, lower.tail = FALSE)
# abs(wald1)
# 
# 
# ## 2do modelo (grupo 3)
# 
# wald2 <- coeficientes[2,]/desvios[2,]
# 
# pnorm(abs(wald2), lower.tail = FALSE)
# pchisq(wald2^2, df = 1, lower.tail = F)
# 
# qnorm(0.05, lower.tail = FALSE)
# abs(wald2)
# 
# ## 3er modelo (grupo 4)
# 
# wald3 <- coeficientes[3,]/desvios[3,]
# 
# pnorm(abs(wald3), lower.tail = FALSE)
# pchisq(wald3^2, df = 1, lower.tail = F)
# 
# qnorm(0.05, lower.tail = FALSE)
# abs(wald3)
```



```{r error aparente}
#Prediction

predict_mod_multinomial <- predict(mod_multinomial, newdata = datos_disc_multinom , "probs") 
round(predict_mod_multinomial, 4)
classpredict <- predict(mod_multinomial, newdata = datos_disc_multinom , "class") #Son las clasificaciones predichas

#Matriz de difusión
tabla1 <- table(datos_disc_multinom$grupos_acp2,classpredict) #Para los datos con los que se hizo el modelo


round((sum(diag(tabla1))/sum(tabla1))*100,2) 

```


Para determinar si se cuenta con un buen modelo y validarlo se recurre a analizar los errores de clasificación, para lo cual se hace uso de matrices de difusión en las que se expresa para cada grupo tanto la cantidad de observaciones clasificadas en el grupo correcto (valores de la diagonal de la matriz) como en los otros grupos (valores fuera de la diagonal). Para obtener la matriz de difusión se debe definir la forma con la que se calculan los errores. Una primera opción es calcular el error aparente, cuyo resultado se observa en el Cuadro 4, donde las columnas representan el grupo predicho por el modelo y las filas el grupo real. 

```{r tabla error aparente, results='asis', include=TRUE}
tabla1 %>% xtable(caption = "Matriz de difusión, error aparente")

```

Para calcular el error aparente se construye el modelo con todas las observaciones y para cada una de ellas se compara el grupo predicho por el modelo con el grupo al que efectivamente pertenece. Así se puede calcular la proporción total de aciertos como la traza de la matriz de difusión sobre el total de observaciones. El modelo planteado tiene un porcentaje de acierto de 95.78%, ocurriendo la mayor proporción de error en el grupo 4, donde de los 3 países 2 son clasificados correctamente. Para las observaciones del grupo 3 no se cometen errores de clasificación. No obstante al tomar en cuenta el error aparente se usan las mismas observaciones para calcular el error y validar el modelo que para construirlo, lo cual puede llevar a un caso de sobreajuste, situación en la cual el modelo funciona bien para la muestra considerada pero no para nuevos datos. Para no caer en esta situación una opción es recurrir a dividir la muestra en una submuestra de entrenamiento y otra de prueba. En este método se estima el modelo con el conjunto de observaciones de entrenamiento y se calcula el error que comete al predecir el grupo de las observaciones del conjunto de prueba. Esta forma de validación funcionará mejor si se cuenta con una muestra de tamaño considerable, si la muestra es muy pequeña el error será muy susceptible a las observaciones que se seleccionan para los grupos de entrenamiento y prueba. Se toma una muestra de prueba del 15% de los países (25), debe tenerse en cuenta que al contar con un grupo de solo 3 observaciones puede ocurrir que en alguna de las submuestras no haya observaciones de esté grupo. Dada la muestra tomada se da que los tres países del grupo 4 quedan en el conjunto de entrenamiento,  por lo tanto en este caso particular no se tiene una medida del error de predicción para este grupo, lo que representa una limitante del modelo. 


```{r entrenamiento y prueba}
#dividir en entrenamiento y prueba
set.seed(3652)
muestra <- sample.int(n = nrow(datos_disc_multinom), size = floor(0.85*nrow(datos_disc_multinom)), replace = F)


entrenamiento <- datos_disc_multinom[muestra, ]
testeo  <- datos_disc_multinom[-muestra, ]

multinom_entrena <- multinom(as.factor(grupos_acp2) ~ gdppercap + medage + noinfectionrate + healthexp + hospitalbed + CESI_INDEX   ,  data=entrenamiento) 



predtesteo<-predict(multinom_entrena,testeo)
predentrena<-predict(multinom_entrena,entrenamiento)

tabla_e <- table(entrenamiento$grupos_acp2,predentrena)
tabla_t <- table(testeo$grupos_acp2,predtesteo)

round((sum(diag(tabla_e))/sum(tabla_e))*100,2)

round((sum(diag(tabla_t))/sum(tabla_t))*100,2)
```


```{r tabla error pred, results='asis', include=TRUE}

tabla_t %>% xtable(caption = "Matriz de difusión, error en muestra de prueba")

```

En el Cuadro 5 se muestra la matriz de difusión para el conjunto de prueba, se aprecia como el modelo predice que una de las observaciones estará en el grupo 4 cuando el grupo real es el 3, mientras que todos los países de los grupos 1 y 2 son clasificados correctamente. El porcentaje de acierto en el grupo de prueba es de 96%, lo que indica una buena capacidad predictiva del modelo con los grupos distintos al 4.


# Conclusiones

En el análisis de cluster, se llegó a que la estructura de clasificación de los países preferida es la de 4 grupos, a partir del análisis simultáneo de los distintos indicadores: variabilidad explicada por el modelo ($R^2$), heterogeneidad dentro de los grupos (pseudo-t), heterogeneidad entre los distintos grupos (pseudo-F) y calidad de representación de las observaciones (siluetas). Los grupos de la estructura propuesta son fácilmente distinguibles en el primer plano principal de las componentes principales construidas en Marsella y Saldaña (2021): el grupo 1 caracteriza los países con menor desarrollo económico que a su vez tienen bajas tasas de infección de COVID-19 a marzo de 2020, el grupo 2 a los países de un mayor nivel económico y bajos niveles de infección, el grupo 3 también a los desarrollados económicamente pero con tasas de infección más altas, mientras que el grupo 4 agrupa a las observaciones atípicas San Marino, Luxemburgo e Islandia, que presentaban niveles de desarrollo económico altos y valores extremos en las tasas de infección. Esta caracterización en el plano se verifica por ejemplo para el PBI per cápita y la tasa de infección, variables originales utilizadas para construir las componentes principales. Las dos componentes explicaban un 72.77% de la inercia global, lo cual significa que hay poca pérdida de información respecto de las variables originales. Al realizar el análisis discriminante logístico con las variables originales se logró clasificar a los países en los grupos con un error aparente reducido, los clusters construidos con las componentes del ACP son coherentes con la clasificación a la que se llega con las variables originales, lo cual se relaciona con el hecho de que para ambos análisis estamos utilizando fundamentalmente la misma información, solo que expresada a través de distintas variables y de forma resumida en el caso de las componentes principales. Al realizar la validación del modelo dividiendo los datos en submuestras de entrenamiento y testeo, el modelo planteado presentó como limitación problemas para clasificar a los países del grupo 4, dado el tamaño reducido de este grupo, mientras que no presentó problemas para la validación de la clasificación de los otros grupos.


# Referencias

* Jorge Blanco. (2006). *Introducción al Análisis Multivariado*. Montevideo: IESTA.

* C. Elgin, G. Basbug y A. Salaman. (2020). *Economic Policy Responses to a Pandemic: Developing the COVID-19 Economic Stimulus Index*. CEPR Press.

* D. Hosmer y S. Lemeshow. (2000). *Applied Logistic Regression. Segunda Edición*. John Wiley &  Sons, Inc.

* Laura Nalbarte. (2020). *Análisis Multivariado I - Análisis de Cluster*. Montevideo: IESTA.

* Laura Nalbarte. (2020). *Análisis Multivariado I - Análisis Discriminante*. Montevideo: IESTA.

* Hadley Wickham, Romain François, Lionel Henry and
  Kirill Müller (2021). dplyr: A Grammar of Data
  Manipulation. R package version 1.0.6.
  https://CRAN.R-project.org/package=dplyr

* H. Wickham. ggplot2: Elegant Graphics for Data
  Analysis. Springer-Verlag New York, 2016.

* David B. Dahl, David Scott, Charles Roosen, Arni
  Magnusson and Jonathan Swinton (2019). xtable:
  Export Tables to LaTeX or HTML. R package version
  1.8-4. https://CRAN.R-project.org/package=xtable

* Sebastien Le, Julie Josse, Francois Husson (2008).
  FactoMineR: An R Package for Multivariate Analysis.
  Journal of Statistical Software, 25(1), 1-18.
  10.18637/jss.v025.i01
  
* Hadley Wickham (2021). forcats: Tools for Working
  with Categorical Variables (Factors). R package
  version 0.5.1.
  https://CRAN.R-project.org/package=forcats
  
* Baptiste Auguie (2017). gridExtra: Miscellaneous
  Functions for "Grid" Graphics. R package version
  2.3. https://CRAN.R-project.org/package=gridExtra
  
* Alboukadel Kassambara and Fabian Mundt (2020).
  factoextra: Extract and Visualize the Results of
  Multivariate Data Analyses. R package version 1.0.7.
  https://CRAN.R-project.org/package=factoextra

* Andrie de Vries and Brian D. Ripley (2020).
  ggdendro: Create Dendrograms and Tree Diagrams Using
  'ggplot2'. R package version 0.1.22.
  https://CRAN.R-project.org/package=ggdendro
  
*  Malika Charrad, Nadia Ghazzali, Veronique Boiteau,
  Azam Niknafs (2014). NbClust: An R Package for
  Determining the Relevant Number of Clusters in a
  Data Set. Journal of Statistical Software, 61(6),
  1-36. URL http://www.jstatsoft.org/v61/i06/.
 
* Maechler, M., Rousseeuw, P., Struyf, A., Hubert, M., Hornik, K.(2021). cluster: Cluster Analysis  Basics and Extensions. R package version 2.1.2.

* Venables, W. N. & Ripley, B. D. (2002) Modern Applied
  Statistics with S. Fourth Edition. Springer, New York. ISBN
  0-387-95457-0
  
* Michael Friendly (2010). HE Plots for Repeated Measures
  Designs. Journal of Statistical Software, 37(4), 1-40. URL
  https://www.jstatsoft.org/v37/i04/.  

* Marcello D'Orazio (2020). StatMatch: Statistical Matching or
  Data Fusion. R package version 1.4.0.
  https://CRAN.R-project.org/package=StatMatch

* Barret Schloerke, Di Cook, Joseph Larmarange, Francois Briatte,
  Moritz Marbach, Edwin Thoen, Amos Elberg and Jason Crowley
  (2021). GGally: Extension to 'ggplot2'. R package version
  2.1.2. https://CRAN.R-project.org/package=GGally
  
* Xavier Robin, Natacha Turck, Alexandre Hainard, Natalia
  Tiberti, Frédérique Lisacek, Jean-Charles Sanchez and Markus
  Müller (2011). pROC: an open-source package for R and S+ to
  analyze and compare ROC curves. BMC Bioinformatics, 12, p. 77.
  DOI: 10.1186/1471-2105-12-77
  <http://www.biomedcentral.com/1471-2105/12/77/>
  
* Max Kuhn (2021). caret: Classification and Regression Training.
  R package version 6.0-88.
  https://CRAN.R-project.org/package=caret
  
* Christian Kleiber and Achim Zeileis (2008). Applied
  Econometrics with R. New York: Springer-Verlag. ISBN
  978-0-387-77316-2. URL https://CRAN.R-project.org/package=AER
  
\newpage

# Anexo

```{r tabla p vals, include=TRUE, results='asis'}
tabla <- tests_wald_multinom %>% as.numeric %>% matrix(., nrow=21, ncol=4)

rownames(tabla) <- as.character(attributes(tests_wald_multinom)$dimnames[[1]])

colnames(tabla) <- as.character(attributes(tests_wald_multinom)$dimnames[[2]])

tabla %>% as.data.frame() %>% xtable(caption="Estimaciones de los parámetros del modelo de regresión logística multinomial, para cada grupo distinto del de referencia.")
         
```

<!-- # Anexos script -->



<!-- ### Cluster con todas las variables -->


```{r cluster anexo 1}
#primer cluster, metodo de ward con las variables originales, la función ya de por si estandariza
clust1 <- agnes(datos[,vars_cluster1], method = "ward", diss = FALSE, stand = TRUE) #con san marino
clust1.1<- agnes(datos[-130, vars_cluster1], method = "ward", diss = FALSE, stand = TRUE) #sin san marino

#DENDOGRAMAS

fviz_dend(clust1,cex=0.4) #con san marino

```

```{r indicadores anexo 1}
#se puede ver un problema de atipicos que conforman un cluster separado

clust1_indicadores <- indicadores(clust1$merge ,datos[,vars_cluster1] ,10 )


distancias1 <- get_dist(datos[,vars_cluster1], method = "euclidean", stand = TRUE)
silueta1<-silhouette(cutree(clust1 ,3) , distancias1)
```


```{r sil anexo 1}
fviz_silhouette(silueta1, print.summary = TRUE) + theme(axis.text.y=element_blank(), axis.ticks.y=element_blank())
```


```{r dendrograma1.1}
#sin san marino

fviz_dend(clust1.1,cex=0.4)  #dendograma sin san marino


clust1.1_indicadores <- indicadores(clust1.1$merge ,datos[-130,vars_cluster1] ,10 )


distancias1.1 <- get_dist(datos[-130,vars_cluster1], method = "euclidean", stand = TRUE)
silueta1.1<-silhouette(cutree(clust1.1 ,3) , distancias1.1)

fviz_silhouette(silueta1.1, print.summary = TRUE)
```


<!-- ### Cluster CESI_INDEX y otras variables -->

```{r cluster}
#Metodo de Ward y variables originales


row.names(datos) <- datos$country

datos_clustr <- scale(datos[,vars_cluster])

#primer cluster, la función ya de por si estandariza
cluster <- agnes(datos_clustr, method = "ward", diss = FALSE) 

```



```{r }
fviz_dend(cluster,cex=0.4) #dendograma ward y variables originales

#se puede ver un problema de atipicos que conforman un cluster separado

cluster_indicadores <- indicadores(cluster$merge ,datos[,vars_cluster] ,10 )


grupos2 <- cutree(cluster, 2)

datos$grupo2 <- grupos2

datos %>% filter(grupos2 == 2)
datos %>% filter(grupos2 == 1)

datos %>% arrange(desc(infectionrate))


distancias <- get_dist(datos[,vars_cluster], method = "euclidean", stand = TRUE)
silueta2<-silhouette(cutree(cluster , 2) , distancias)


#grafico de silueta, vemos que hay un conjunto de observaciones del grupo 2 con valores negativos
fviz_silhouette(silueta2, print.summary = TRUE)


#vemos cuales son los paises con valores negativos de la silueta
a <- rep(0,166)
a[which(silueta2[1:166,3]<0)] <- 1

datos$aux <- a


datosaux <- datos %>% filter(grupos2 == 3)
datosaux %>% filter(aux==1)

#se puede apreciar que considerando la variable infectionrate se diferencian en varianza del conjunto del resto de los paises y los valores se acumulan mas cercanamente al cero.
ggplot(datosaux)+geom_boxplot(aes(x=as.factor(aux), y = infectionrate))
ggplot(datosaux)+geom_boxplot(aes(x=as.factor(aux), y = gdppercap))

ggplot(datosaux) + geom_point(aes(x = as.factor(aux), y = infectionrate))

```






<!-- ### Cluster vecino más cercano -->

```{r otros cluster jerarquicos}
clust2.1 <- agnes(datos[,vars_cluster], method = "single", diss = FALSE, stand = TRUE) #vecino mas cercano

clust2.2 <- agnes(datos[,vars_cluster], method = "complete", diss = FALSE, stand = TRUE) #vecino mas lejano

#se puede notar a san marino como outlier
fviz_dend(clust2.1,cex=0.4)


#se pueden notar que san marino islandia y luxemburgo son los ultimos en agruparse
fviz_dend(clust2.2,cex=0.4)

clust2.3 <- agnes(datos[-c(130, 92,70),vars_cluster], method = "complete", diss = FALSE, stand = TRUE) #sacamos a los outliers para ver que pasa

fviz_dend(clust2.3,cex=0.4) #ahora otras observaciones pasan a ser las outliers

clust2.3_nroclust <- indicadores(clust2.3$merge ,datos[-c(130, 92,70),vars_cluster] ,10 ) #indicadores




```


